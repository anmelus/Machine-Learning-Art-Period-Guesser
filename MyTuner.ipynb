{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"MyTuner.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"KrCs-0oucN2P"},"source":["import os\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"id":"KrCs-0oucN2P","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f62b805b","outputId":"04321d40-9443-40b2-fcd3-e74e12fead95"},"source":["# Generate from Folders\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","#test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","#train_generator = train_datagen.flow_from_directory(\n","#        trainFolder,\n","#        batch_size=32,\n","#        class_mode='categorical')\n","#validation_generator = test_datagen.flow_from_directory(\n","#        valFolder,\n","#        batch_size=32,\n","#        class_mode='categorical')\n","\n","# DATA AUGMENTATION via Generator\n","\n","batch_size = 32\n","train_input_shape = (224, 224, 3)\n","n_classes = 10\n","print(n_classes)\n","\n","# is preprocessing line required?\n","shared = \"drive/Shareddrives/Project F Folder/\"\n","trainFolder = shared + \"ImageGenFolder4/train/\"\n","valFolder = shared + \"ImageGenFolder4/val/\"\n","\n","train_datagen = ImageDataGenerator(\n","                                   rescale=1./255.,\n","                                   rotation_range=30,\n","                                   zoom_range=0.5,\n","                                   #horizontal_flip=True,\n","                                   #vertical_flip=True,\n","                                  )\n","\n","val_datagen = ImageDataGenerator(\n","                                   rescale=1./255.,\n","                                   #horizontal_flip=True,\n","                                   #vertical_flip=True,\n","                                  )\n","\n","train_generator = train_datagen.flow_from_directory(directory=trainFolder,\n","                                                    class_mode='categorical',\n","                                                    target_size=train_input_shape[0:2],\n","                                                    batch_size=batch_size,\n","                                                    shuffle=True,\n","                                                   )\n","\n","valid_generator = val_datagen.flow_from_directory(directory=valFolder,\n","                                                    class_mode='categorical',\n","                                                    target_size=train_input_shape[0:2],\n","                                                    batch_size=batch_size,\n","                                                    shuffle=True,\n","                                                   )\n","\n","STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n","print(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)"],"id":"f62b805b","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Radek Pudelko\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n"]},{"name":"stdout","output_type":"stream","text":["10\n","Found 1600 images belonging to 10 classes.\n","Found 400 images belonging to 10 classes.\n","Total number of batches = 50 and 12\n"]}]},{"cell_type":"code","metadata":{"id":"965beffd"},"source":["from tensorflow.keras import layers\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications import ResNet101\n","#from tensorflow_addons.metrics import F1Score\n","\n","\n","class F1_Score(tf.keras.metrics.Metric):\n","\n","    def __init__(self, name='f1_score', **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.f1 = self.add_weight(name='f1', initializer='zeros')\n","        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n","        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        p = self.precision_fn(y_true, y_pred)\n","        r = self.recall_fn(y_true, y_pred)\n","        # since f1 is a variable, we use assign\n","        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n","\n","    def result(self):\n","        return self.f1\n","\n","    def reset_state(self):\n","        # we also need to reset the state of the precision and recall objects\n","        self.precision_fn.reset_states()\n","        self.recall_fn.reset_states()\n","        self.f1.assign(0)\n","\n","\n","\n","Metrics = [\"acc\",\"Precision\", \"Recall\", F1_Score()]\n","\n","\n","def FCN3(base, dense1, dense2):\n","    MY_SIZE = 224\n","    IMG_SIZE = (MY_SIZE,MY_SIZE)\n","    IMG_SHAPE = IMG_SIZE + (3,)\n","\n","    model = tf.keras.Sequential([\n","        base.layers[0],\n","        base.layers[1],\n","        \n","        layers.Dense(dense1, activation=\"relu\"),\n","        layers.Dropout(.5),\n","        layers.BatchNormalization(),\n","        \n","        layers.Dense(dense2, activation=\"relu\"),\n","        layers.Dropout(.5),\n","        layers.BatchNormalization(),\n","        \n","        layers.Dense(n_classes, activation = \"softmax\"),   \n","    ])\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n","        loss='categorical_crossentropy',\n","        metrics=Metrics)\n","    return model\n"],"id":"965beffd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3863554b"},"source":["patience = 6\n","earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_f1_score\", patience=patience,restore_best_weights=False, mode=\"max\", verbose=1)\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1_score', factor=0.1,patience=3, \n","                              verbose=1, mode='max')\n","\n"],"id":"3863554b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"473e5174","outputId":"36a2d0a7-c158-438a-df1b-a8da51289ffe"},"source":["models = []\n","histories = []\n","allTrials = []\n","trials = []\n","results = []\n","\n","dense1 = list(range(128,512,64))\n","dense2 = list(range(32,256,32))\n","\n","combos = []\n","for d1 in dense1:\n","    for d2 in dense2:\n","        combos.append([d1,d2])\n","print(len(combos))\n"],"id":"473e5174","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["42\n"]}]},{"cell_type":"code","metadata":{"id":"fd56a41d","outputId":"1e9937d6-f24b-4959-cde5-5a94cbd94d48"},"source":["import os\n","# Load the results from previous runs \n","resultsFile = shared + \"myResults3.csv\"\n","if os.path.exists(resultsFile):\n","    with open(resultsFile, \"r\") as out:\n","        raw = out.readlines()\n","        for line in raw[1:]:\n","            line = line.split(\",\")\n","            combo = [int(line[0]), int(line[1])]\n","            if combo in combos:\n","                print(combo)\n","                combos.pop(combos.index(combo))\n","            allTrials.append(combo)\n","            result = [float(line[2]), float(line[3]), float(line[4]), float(line[5]), float(line[6])]\n","            results.append(result)\n","print(len(combos))"],"id":"fd56a41d","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[448, 224]\n","41\n"]}]},{"cell_type":"code","metadata":{"id":"de9b302e","outputId":"9ae28c9a-f3e7-44c4-dc19-c27f17eb9ea3"},"source":["import random\n","\n","\n","for i in range(5):\n","    \n","    randI = random.randint(0, len(combos)-1)\n","    combo = combos.pop(randI)\n","    trials.append(combo)\n","    print(i, combo[0], combo[1])\n","    base = tf.keras.models.load_model(shared + 'myBaseModel.h5', custom_objects={\"F1_Score\": F1_Score})\n","    myModel = FCN3(base, combo[0], combo[1])\n","    modelPath = shared + \"models/model_\" + str(combo[0]) + \"_\" + str(combo[1]) + \".h5\"\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        modelPath, monitor='val_f1_score', verbose=1, save_best_only=True,\n","        save_weights_only=False, mode='max', save_freq='epoch',\n","        options=None)\n","    history = myModel.fit(train_generator, validation_data = valid_generator, epochs=100, verbose = 1,\n","                      callbacks=[earlystopping, reduce_lr, checkpoint])\n","    histories.append(history)\n","    models.append(myModel)\n","    print(\"\\n\\n\\n\\n#################################################\")\n","    print(\"#################################################\")\n","    print(\"#################################################\\n\\n\\n\\n\")\n","    "],"id":"de9b302e","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["0 192 224\n","Epoch 1/100\n","50/50 [==============================] - 36s 537ms/step - loss: 2.0132 - acc: 0.3281 - precision: 0.5336 - recall: 0.1587 - f1_score: 0.2447 - val_loss: 0.9602 - val_acc: 0.7275 - val_precision: 0.9000 - val_recall: 0.5625 - val_f1_score: 0.6923\n","\n","Epoch 00001: val_f1_score improved from -inf to 0.69231, saving model to models\\model_192_224.h5\n"]},{"name":"stderr","output_type":"stream","text":["c:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","50/50 [==============================] - 26s 522ms/step - loss: 1.2581 - acc: 0.6000 - precision: 0.7888 - recall: 0.3969 - f1_score: 0.5281 - val_loss: 0.5610 - val_acc: 0.8525 - val_precision: 0.9177 - val_recall: 0.7525 - val_f1_score: 0.8269\n","\n","Epoch 00002: val_f1_score improved from 0.69231 to 0.82692, saving model to models\\model_192_224.h5\n","Epoch 3/100\n","50/50 [==============================] - 25s 505ms/step - loss: 0.9864 - acc: 0.6981 - precision: 0.8538 - recall: 0.5400 - f1_score: 0.6616 - val_loss: 0.7740 - val_acc: 0.7775 - val_precision: 0.8534 - val_recall: 0.7275 - val_f1_score: 0.7854\n","\n","Epoch 00003: val_f1_score did not improve from 0.82692\n","Epoch 4/100\n","50/50 [==============================] - 25s 501ms/step - loss: 0.8384 - acc: 0.7437 - precision: 0.8758 - recall: 0.6081 - f1_score: 0.7178 - val_loss: 0.7240 - val_acc: 0.7500 - val_precision: 0.8593 - val_recall: 0.7025 - val_f1_score: 0.7730\n","\n","Epoch 00004: val_f1_score did not improve from 0.82692\n","Epoch 5/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.6587 - acc: 0.8144 - precision: 0.9145 - recall: 0.7088 - f1_score: 0.7986 - val_loss: 0.5770 - val_acc: 0.8125 - val_precision: 0.8846 - val_recall: 0.7475 - val_f1_score: 0.8103\n","\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","\n","Epoch 00005: val_f1_score did not improve from 0.82692\n","Epoch 6/100\n","50/50 [==============================] - 25s 503ms/step - loss: 0.6125 - acc: 0.8325 - precision: 0.9119 - recall: 0.7181 - f1_score: 0.8035 - val_loss: 0.5089 - val_acc: 0.8425 - val_precision: 0.9096 - val_recall: 0.7800 - val_f1_score: 0.8398\n","\n","Epoch 00006: val_f1_score improved from 0.82692 to 0.83984, saving model to models\\model_192_224.h5\n","Epoch 7/100\n","50/50 [==============================] - 25s 501ms/step - loss: 0.5636 - acc: 0.8456 - precision: 0.9330 - recall: 0.7394 - f1_score: 0.8250 - val_loss: 0.5226 - val_acc: 0.8375 - val_precision: 0.9159 - val_recall: 0.7900 - val_f1_score: 0.8483\n","\n","Epoch 00007: val_f1_score improved from 0.83984 to 0.84832, saving model to models\\model_192_224.h5\n","Epoch 8/100\n","50/50 [==============================] - 25s 503ms/step - loss: 0.5341 - acc: 0.8544 - precision: 0.9333 - recall: 0.7519 - f1_score: 0.8328 - val_loss: 0.5382 - val_acc: 0.8350 - val_precision: 0.9043 - val_recall: 0.7800 - val_f1_score: 0.8376\n","\n","Epoch 00008: val_f1_score did not improve from 0.84832\n","Epoch 9/100\n","50/50 [==============================] - 25s 502ms/step - loss: 0.5080 - acc: 0.8631 - precision: 0.9408 - recall: 0.7644 - f1_score: 0.8434 - val_loss: 0.4976 - val_acc: 0.8450 - val_precision: 0.9114 - val_recall: 0.7975 - val_f1_score: 0.8507\n","\n","Epoch 00009: val_f1_score improved from 0.84832 to 0.85067, saving model to models\\model_192_224.h5\n","Epoch 10/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.4794 - acc: 0.8819 - precision: 0.9564 - recall: 0.7806 - f1_score: 0.8596 - val_loss: 0.5211 - val_acc: 0.8450 - val_precision: 0.8966 - val_recall: 0.7800 - val_f1_score: 0.8342\n","\n","Epoch 00010: val_f1_score did not improve from 0.85067\n","Epoch 11/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.4740 - acc: 0.8763 - precision: 0.9458 - recall: 0.7856 - f1_score: 0.8583 - val_loss: 0.5746 - val_acc: 0.8275 - val_precision: 0.8946 - val_recall: 0.7850 - val_f1_score: 0.8362\n","\n","Epoch 00011: val_f1_score did not improve from 0.85067\n","Epoch 12/100\n","50/50 [==============================] - 25s 501ms/step - loss: 0.4849 - acc: 0.8675 - precision: 0.9374 - recall: 0.7763 - f1_score: 0.8492 - val_loss: 0.5859 - val_acc: 0.8325 - val_precision: 0.8966 - val_recall: 0.7800 - val_f1_score: 0.8342\n","\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","\n","Epoch 00012: val_f1_score did not improve from 0.85067\n","Epoch 13/100\n","50/50 [==============================] - 25s 502ms/step - loss: 0.4667 - acc: 0.8869 - precision: 0.9412 - recall: 0.7906 - f1_score: 0.8594 - val_loss: 0.5714 - val_acc: 0.8375 - val_precision: 0.8997 - val_recall: 0.7850 - val_f1_score: 0.8385\n","\n","Epoch 00013: val_f1_score did not improve from 0.85067\n","Epoch 14/100\n","50/50 [==============================] - 25s 503ms/step - loss: 0.4583 - acc: 0.8813 - precision: 0.9476 - recall: 0.7906 - f1_score: 0.8620 - val_loss: 0.5600 - val_acc: 0.8400 - val_precision: 0.9026 - val_recall: 0.7875 - val_f1_score: 0.8411\n","\n","Epoch 00014: val_f1_score did not improve from 0.85067\n","Epoch 15/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.4609 - acc: 0.8850 - precision: 0.9468 - recall: 0.8012 - f1_score: 0.8680 - val_loss: 0.5497 - val_acc: 0.8450 - val_precision: 0.9054 - val_recall: 0.7900 - val_f1_score: 0.8438\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n","\n","Epoch 00015: val_f1_score did not improve from 0.85067\n","Epoch 00015: early stopping\n","\n","\n","\n","\n","#################################################\n","#################################################\n","#################################################\n","\n","\n","\n","\n","1 384 160\n","Epoch 1/100\n","50/50 [==============================] - 30s 523ms/step - loss: 1.8679 - acc: 0.3900 - precision: 0.6051 - recall: 0.2087 - f1_score: 0.4481 - val_loss: 1.0018 - val_acc: 0.6925 - val_precision: 0.8050 - val_recall: 0.5675 - val_f1_score: 0.6657\n","\n","Epoch 00001: val_f1_score improved from -inf to 0.66569, saving model to models\\model_384_160.h5\n","Epoch 2/100\n","50/50 [==============================] - 25s 504ms/step - loss: 1.0442 - acc: 0.6769 - precision: 0.8284 - recall: 0.5038 - f1_score: 0.6265 - val_loss: 0.5500 - val_acc: 0.8250 - val_precision: 0.8870 - val_recall: 0.7650 - val_f1_score: 0.8215\n","\n","Epoch 00002: val_f1_score improved from 0.66569 to 0.82148, saving model to models\\model_384_160.h5\n","Epoch 3/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.7702 - acc: 0.7750 - precision: 0.8856 - recall: 0.6388 - f1_score: 0.7422 - val_loss: 0.6005 - val_acc: 0.8250 - val_precision: 0.8631 - val_recall: 0.7725 - val_f1_score: 0.8153\n","\n","Epoch 00003: val_f1_score did not improve from 0.82148\n","Epoch 4/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.6358 - acc: 0.8231 - precision: 0.9095 - recall: 0.7156 - f1_score: 0.8010 - val_loss: 0.5593 - val_acc: 0.8425 - val_precision: 0.8960 - val_recall: 0.7750 - val_f1_score: 0.8311\n","\n","Epoch 00004: val_f1_score improved from 0.82148 to 0.83110, saving model to models\\model_384_160.h5\n","Epoch 5/100\n","50/50 [==============================] - 25s 506ms/step - loss: 0.5577 - acc: 0.8581 - precision: 0.9208 - recall: 0.7625 - f1_score: 0.8342 - val_loss: 0.6241 - val_acc: 0.8250 - val_precision: 0.8768 - val_recall: 0.7650 - val_f1_score: 0.8171\n","\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","\n","Epoch 00005: val_f1_score did not improve from 0.83110\n","Epoch 6/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.4645 - acc: 0.8856 - precision: 0.9487 - recall: 0.7981 - f1_score: 0.8669 - val_loss: 0.4673 - val_acc: 0.8650 - val_precision: 0.9167 - val_recall: 0.8250 - val_f1_score: 0.8684\n","\n","Epoch 00006: val_f1_score improved from 0.83110 to 0.86842, saving model to models\\model_384_160.h5\n","Epoch 7/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.4175 - acc: 0.8938 - precision: 0.9516 - recall: 0.8238 - f1_score: 0.8831 - val_loss: 0.4264 - val_acc: 0.8775 - val_precision: 0.9276 - val_recall: 0.8325 - val_f1_score: 0.8775\n","\n","Epoch 00007: val_f1_score improved from 0.86842 to 0.87747, saving model to models\\model_384_160.h5\n","Epoch 8/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.3877 - acc: 0.9000 - precision: 0.9465 - recall: 0.8300 - f1_score: 0.8844 - val_loss: 0.4269 - val_acc: 0.8700 - val_precision: 0.9300 - val_recall: 0.8300 - val_f1_score: 0.8771\n","\n","Epoch 00008: val_f1_score did not improve from 0.87747\n","Epoch 9/100\n","50/50 [==============================] - 25s 505ms/step - loss: 0.3978 - acc: 0.8994 - precision: 0.9521 - recall: 0.8319 - f1_score: 0.8879 - val_loss: 0.4483 - val_acc: 0.8725 - val_precision: 0.9278 - val_recall: 0.8350 - val_f1_score: 0.8789\n","\n","Epoch 00009: val_f1_score improved from 0.87747 to 0.87895, saving model to models\\model_384_160.h5\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/100\n","50/50 [==============================] - 25s 505ms/step - loss: 0.3761 - acc: 0.9075 - precision: 0.9551 - recall: 0.8500 - f1_score: 0.8995 - val_loss: 0.4294 - val_acc: 0.8775 - val_precision: 0.9272 - val_recall: 0.8275 - val_f1_score: 0.8745\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","\n","Epoch 00010: val_f1_score did not improve from 0.87895\n","Epoch 11/100\n","50/50 [==============================] - 25s 504ms/step - loss: 0.3433 - acc: 0.9175 - precision: 0.9544 - recall: 0.8506 - f1_score: 0.8995 - val_loss: 0.4316 - val_acc: 0.8775 - val_precision: 0.9274 - val_recall: 0.8300 - val_f1_score: 0.8760\n","\n","Epoch 00011: val_f1_score did not improve from 0.87895\n","Epoch 12/100\n","50/50 [==============================] - 26s 515ms/step - loss: 0.3597 - acc: 0.9162 - precision: 0.9492 - recall: 0.8525 - f1_score: 0.8983 - val_loss: 0.4316 - val_acc: 0.8775 - val_precision: 0.9274 - val_recall: 0.8300 - val_f1_score: 0.8760\n","\n","Epoch 00012: val_f1_score did not improve from 0.87895\n","Epoch 13/100\n","50/50 [==============================] - 26s 515ms/step - loss: 0.3782 - acc: 0.9025 - precision: 0.9508 - recall: 0.8338 - f1_score: 0.8884 - val_loss: 0.4282 - val_acc: 0.8775 - val_precision: 0.9278 - val_recall: 0.8350 - val_f1_score: 0.8789\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n","\n","Epoch 00013: val_f1_score did not improve from 0.87895\n","Epoch 14/100\n","50/50 [==============================] - 26s 513ms/step - loss: 0.3605 - acc: 0.9144 - precision: 0.9511 - recall: 0.8381 - f1_score: 0.8910 - val_loss: 0.4313 - val_acc: 0.8775 - val_precision: 0.9304 - val_recall: 0.8350 - val_f1_score: 0.8801\n","\n","Epoch 00014: val_f1_score improved from 0.87895 to 0.88010, saving model to models\\model_384_160.h5\n","Epoch 15/100\n","50/50 [==============================] - 26s 506ms/step - loss: 0.3298 - acc: 0.9212 - precision: 0.9655 - recall: 0.8569 - f1_score: 0.9079 - val_loss: 0.4320 - val_acc: 0.8775 - val_precision: 0.9300 - val_recall: 0.8300 - val_f1_score: 0.8771\n","\n","Epoch 00015: val_f1_score did not improve from 0.88010\n","Epoch 16/100\n","50/50 [==============================] - 26s 506ms/step - loss: 0.3902 - acc: 0.8956 - precision: 0.9403 - recall: 0.8263 - f1_score: 0.8796 - val_loss: 0.4354 - val_acc: 0.8750 - val_precision: 0.9298 - val_recall: 0.8275 - val_f1_score: 0.8757\n","\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n","\n","Epoch 00016: val_f1_score did not improve from 0.88010\n","Epoch 17/100\n","50/50 [==============================] - 26s 508ms/step - loss: 0.3357 - acc: 0.9206 - precision: 0.9606 - recall: 0.8537 - f1_score: 0.9040 - val_loss: 0.4316 - val_acc: 0.8775 - val_precision: 0.9304 - val_recall: 0.8350 - val_f1_score: 0.8801\n","\n","Epoch 00017: val_f1_score did not improve from 0.88010\n","Epoch 18/100\n","50/50 [==============================] - 26s 508ms/step - loss: 0.3781 - acc: 0.9050 - precision: 0.9509 - recall: 0.8475 - f1_score: 0.8962 - val_loss: 0.4305 - val_acc: 0.8775 - val_precision: 0.9330 - val_recall: 0.8350 - val_f1_score: 0.8813\n","\n","Epoch 00018: val_f1_score improved from 0.88010 to 0.88127, saving model to models\\model_384_160.h5\n","Epoch 19/100\n","50/50 [==============================] - 26s 506ms/step - loss: 0.3828 - acc: 0.9087 - precision: 0.9502 - recall: 0.8469 - f1_score: 0.8956 - val_loss: 0.4322 - val_acc: 0.8775 - val_precision: 0.9328 - val_recall: 0.8325 - val_f1_score: 0.8798\n","\n","Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n","\n","Epoch 00019: val_f1_score did not improve from 0.88127\n","Epoch 20/100\n","50/50 [==============================] - 26s 508ms/step - loss: 0.3308 - acc: 0.9231 - precision: 0.9671 - recall: 0.8644 - f1_score: 0.9129 - val_loss: 0.4323 - val_acc: 0.8775 - val_precision: 0.9330 - val_recall: 0.8350 - val_f1_score: 0.8813\n","\n","Epoch 00020: val_f1_score did not improve from 0.88127\n","Epoch 21/100\n","50/50 [==============================] - 26s 507ms/step - loss: 0.3243 - acc: 0.9244 - precision: 0.9735 - recall: 0.8725 - f1_score: 0.9202 - val_loss: 0.4315 - val_acc: 0.8775 - val_precision: 0.9330 - val_recall: 0.8350 - val_f1_score: 0.8813\n","\n","Epoch 00021: val_f1_score did not improve from 0.88127\n","Epoch 22/100\n","50/50 [==============================] - 26s 507ms/step - loss: 0.3574 - acc: 0.9156 - precision: 0.9624 - recall: 0.8469 - f1_score: 0.9009 - val_loss: 0.4295 - val_acc: 0.8775 - val_precision: 0.9330 - val_recall: 0.8350 - val_f1_score: 0.8813\n","\n","Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n","\n","Epoch 00022: val_f1_score did not improve from 0.88127\n","Epoch 23/100\n","50/50 [==============================] - 26s 507ms/step - loss: 0.3554 - acc: 0.9119 - precision: 0.9559 - recall: 0.8544 - f1_score: 0.9023 - val_loss: 0.4316 - val_acc: 0.8775 - val_precision: 0.9328 - val_recall: 0.8325 - val_f1_score: 0.8798\n","\n","Epoch 00023: val_f1_score did not improve from 0.88127\n","Epoch 24/100\n","50/50 [==============================] - 26s 510ms/step - loss: 0.3432 - acc: 0.9137 - precision: 0.9598 - recall: 0.8512 - f1_score: 0.9023 - val_loss: 0.4335 - val_acc: 0.8775 - val_precision: 0.9302 - val_recall: 0.8325 - val_f1_score: 0.8786\n","\n","Epoch 00024: val_f1_score did not improve from 0.88127\n","Epoch 00024: early stopping\n","\n","\n","\n","\n","#################################################\n","#################################################\n","#################################################\n","\n","\n","\n","\n","2 192 128\n","Epoch 1/100\n","50/50 [==============================] - 31s 526ms/step - loss: 2.0678 - acc: 0.3181 - precision: 0.4989 - recall: 0.1419 - f1_score: 0.3982 - val_loss: 1.0547 - val_acc: 0.6875 - val_precision: 0.8354 - val_recall: 0.5075 - val_f1_score: 0.6314\n","\n","Epoch 00001: val_f1_score improved from -inf to 0.63141, saving model to models\\model_192_128.h5\n","Epoch 2/100\n","50/50 [==============================] - 26s 508ms/step - loss: 1.3211 - acc: 0.5769 - precision: 0.7885 - recall: 0.3844 - f1_score: 0.5168 - val_loss: 0.8106 - val_acc: 0.7450 - val_precision: 0.8213 - val_recall: 0.6550 - val_f1_score: 0.7288\n","\n","Epoch 00002: val_f1_score improved from 0.63141 to 0.72879, saving model to models\\model_192_128.h5\n","Epoch 3/100\n","50/50 [==============================] - 26s 511ms/step - loss: 1.0284 - acc: 0.6894 - precision: 0.8454 - recall: 0.4956 - f1_score: 0.6249 - val_loss: 0.5450 - val_acc: 0.8350 - val_precision: 0.8977 - val_recall: 0.7675 - val_f1_score: 0.8275\n","\n","Epoch 00003: val_f1_score improved from 0.72879 to 0.82749, saving model to models\\model_192_128.h5\n","Epoch 4/100\n","46/50 [==========================>...] - ETA: 1s - loss: 0.8703 - acc: 0.7351 - precision: 0.9023 - recall: 0.5774 - f1_score: 0.7042"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mC:\\Users\\RADEKP~1\\AppData\\Local\\Temp/ipykernel_17232/1970536492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         options=None)\n\u001b[0;32m     17\u001b[0m     history = myModel.fit(train_generator, validation_data = valid_generator, epochs=100, verbose = 1,\n\u001b[1;32m---> 18\u001b[1;33m                       callbacks=[earlystopping, reduce_lr, checkpoint])\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[1;32mc:\\users\\radek pudelko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"e12aa245"},"source":["hResults = []\n","resI = -1 - patience\n","for i in range(len(histories)):\n","    hRes = []\n","    hRes.append(histories[i].history[\"val_loss\"][resI])\n","    hRes.append(histories[i].history[\"val_acc\"][resI])\n","    hRes.append(histories[i].history[\"val_precision\"][resI])\n","    hRes.append(histories[i].history[\"val_recall\"][resI])\n","    hRes.append(histories[i].history[\"val_f1_score\"][resI])\n","    print(hRes)\n","    hResults.append(hRes)\n","print()"],"id":"e12aa245","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f88e988e"},"source":["allTrials.extend(trials)\n","results.extend(hResults)\n","print(len(trials))\n","print(len(results))\n","for i in range(len(results)):\n","    print(i, allTrials[i], results[i][-1])\n"],"id":"f88e988e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d43947c9"},"source":["with open(resultsFile, \"w\") as out:\n","    out.write(\"dense1,dense2,loss,acc,prec,recall,f1\\n\")\n","    for i in range(len(results)):\n","        line = str(allTrials[i][0]) + \",\" + str(allTrials[i][1]) + \",\"\n","        line += str(results[i][0])\n","        for res in results[i][1:5]:\n","            print(i, res)\n","            line += \",\" + str(res)\n","        out.write(line + \"\\n\")"],"id":"d43947c9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"416ac2f8"},"source":[""],"id":"416ac2f8","execution_count":null,"outputs":[]}]}